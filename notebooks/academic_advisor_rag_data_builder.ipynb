{"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UASuy8Uk3ABj","executionInfo":{"status":"ok","timestamp":1764346552233,"user_tz":-120,"elapsed":2441,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"ade326af-5693-4abf-b0e3-65bd85e1c461"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"UASuy8Uk3ABj","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","id":"983fcbd5","metadata":{"id":"983fcbd5"},"source":["# Academic Advisor RAG Dataset Builder\n","\n","This notebook converts raw university catalog files into a **clean, structured, RAG-ready JSON dataset**.\n","\n","**Input sources:**\n","- `2025-2026_CSUN_Catalog.epub` (California State University, Northridge)\n","- `UG-Catalog-AY2024-2025-Updates.pdf` (University of the People)\n","\n","**Main steps:**\n","1. Load and parse EPUB (CSUN) and PDF (UoPeople).\n","2. Clean raw text and preserve paragraph structure.\n","3. Chunk text into semantically meaningful segments.\n","4. Classify each chunk into a useful category (admissions, courses, graduation, etc.).\n","5. Infer academic metadata (program, degree, level, college).\n","6. Deduplicate repeated chunks across both catalogs.\n","7. Save final dataset as `academic_advisor_rag_dataset.json`.\n"]},{"cell_type":"code","source":["!pip install PyPDF2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4t0rfRr43d3B","executionInfo":{"status":"ok","timestamp":1764340141654,"user_tz":-120,"elapsed":4797,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"a0af30cc-e04a-495c-fa87-7def71a79dae"},"id":"4t0rfRr43d3B","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}]},{"cell_type":"code","execution_count":5,"id":"3d5b6bbf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3d5b6bbf","executionInfo":{"status":"ok","timestamp":1764340172846,"user_tz":-120,"elapsed":7,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"a60a0e12-e008-4669-b23c-4bc83c0d1cdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configured paths:\n"," - CSUN EPUB:     /content/drive/MyDrive/DAB_RAG_ZakyProject/data/2025-2026_CSUN_Catalog.epub\n"," - UoPeople PDF:  /content/drive/MyDrive/DAB_RAG_ZakyProject/data/UG-Catalog-AY2024-2025-Updates.pdf\n"," - Output JSON:   /content/drive/MyDrive/DAB_RAG_ZakyProject/data/academic_advisor_rag_dataset.json\n"]}],"source":["\"\"\"\n","Step 1: Imports and configuration\n","\n","This cell sets up all required imports and defines file paths\n","for the input catalogs and the output JSON dataset.\n","\"\"\"\n","\n","import os\n","import re\n","import json\n","from zipfile import ZipFile\n","\n","from typing import List, Dict, Tuple, Set\n","\n","# PDF reader library\n","from PyPDF2 import PdfReader\n","\n","# -------------------------------------------------------------------\n","# File path configuration\n","# -------------------------------------------------------------------\n","# NOTE: Adjust these paths if your files are in a different directory.\n","CSUN_EPUB_PATH = \"/content/drive/MyDrive/DAB_RAG_ZakyProject/data/raw/2025-2026_CSUN_Catalog.epub\"\n","UOPEOPLE_PDF_PATH = \"/content/drive/MyDrive/DAB_RAG_ZakyProject/data/raw/UG-Catalog-AY2024-2025-Updates.pdf\"\n","OUTPUT_JSON_PATH = \"/content/drive/MyDrive/DAB_RAG_ZakyProject/data/processed/academic_advisor_rag_dataset.json\"\n","\n","print(\"Configured paths:\")\n","print(f\" - CSUN EPUB:     {CSUN_EPUB_PATH}\")\n","print(f\" - UoPeople PDF:  {UOPEOPLE_PDF_PATH}\")\n","print(f\" - Output JSON:   {OUTPUT_JSON_PATH}\")"]},{"cell_type":"code","execution_count":6,"id":"30653eeb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30653eeb","executionInfo":{"status":"ok","timestamp":1764340190791,"user_tz":-120,"elapsed":35,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"8113f240-9e9e-4504-fa26-343352e02de9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Text cleaning and chunking helpers defined.\n"]}],"source":["\"\"\"\n","Step 2: Text cleaning and chunking helpers\n","\n","These functions:\n","- Clean HTML content from the EPUB while preserving paragraph breaks.\n","- Chunk text into paragraph-based segments suitable for embeddings.\n","\"\"\"\n","\n","def clean_html_content(html: str) -> str:\n","    \"\"\"Clean HTML content while preserving paragraph and line breaks.\n","\n","    Operations:\n","    - Remove <script> and <style> blocks.\n","    - Convert <p> and <br> tags to newline characters.\n","    - Strip all other HTML tags.\n","    - Normalize whitespace and collapse excess blank lines.\n","\n","    Parameters\n","    ----------\n","    html : str\n","        Raw HTML string extracted from the EPUB.\n","\n","    Returns\n","    -------\n","    str\n","        Cleaned text with paragraph breaks maintained.\n","    \"\"\"\n","    # Remove <script> and <style> blocks completely\n","    html = re.sub(r\"(?is)<(script|style).*?>.*?(</\\1>)\", \" \", html)\n","\n","    # Convert <p> and <br> tags into newlines\n","    html = re.sub(r\"(?i)<\\s*(p|br)[^>]*>\", \"\\n\", html)\n","\n","    # Remove all other HTML tags\n","    html = re.sub(r\"(?s)<.*?>\", \" \", html)\n","\n","    # Normalize newlines and spaces\n","    html = html.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n","    html = re.sub(r\"[ \\t]+\", \" \", html)       # collapse multiple spaces\n","    html = re.sub(r\"\\n{3,}\", \"\\n\\n\", html)  # limit blank lines\n","\n","    return html.strip()\n","\n","\n","def chunk_text_by_paragraph(text: str, max_length: int = 1400) -> List[str]:\n","    \"\"\"Chunk text into semantically coherent segments by grouping paragraphs.\n","\n","    Strategy:\n","    - Split on newline characters → get paragraphs.\n","    - Accumulate paragraphs into a buffer until max_length is reached.\n","    - Start a new chunk when the buffer would exceed max_length.\n","\n","    Parameters\n","    ----------\n","    text : str\n","        Clean input text containing newline-separated paragraphs.\n","    max_length : int, optional\n","        Maximum number of characters per chunk, by default 1400.\n","\n","    Returns\n","    -------\n","    List[str]\n","        List of chunk strings, each suitable for embedding.\n","    \"\"\"\n","    if not text:\n","        return []\n","\n","    # Split into non-empty paragraphs\n","    paragraphs = [p.strip() for p in text.split(\"\\n\") if p.strip()]\n","    chunks: List[str] = []\n","    buffer = \"\"\n","\n","    for paragraph in paragraphs:\n","        if buffer and len(buffer) + 1 + len(paragraph) > max_length:\n","            # Flush current buffer as a chunk\n","            chunks.append(buffer.strip())\n","            buffer = paragraph\n","        else:\n","            # Append paragraph to buffer (with newline if not empty)\n","            buffer = (buffer + \"\\n\" + paragraph).strip() if buffer else paragraph\n","\n","    # Append any remaining text in the buffer\n","    if buffer:\n","        chunks.append(buffer.strip())\n","\n","    return chunks\n","\n","\n","print(\"Text cleaning and chunking helpers defined.\")"]},{"cell_type":"code","execution_count":8,"id":"b02a77b3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b02a77b3","executionInfo":{"status":"ok","timestamp":1764340297902,"user_tz":-120,"elapsed":24,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"aed04711-7e21-4d1f-ce50-619c4b680860"},"outputs":[{"output_type":"stream","name":"stdout","text":["Classification and metadata inference helpers defined.\n"]}],"source":["\"\"\"\n","Step 3: Classification and academic metadata inference\n","\n","These functions:\n","- Assign a useful category to each chunk (e.g., admissions, course_description).\n","- Infer program, college, degree, and level from filenames and content.\n","\"\"\"\n","\n","def classify_chunk_category(text: str) -> str:\n","    \"\"\"Classify a chunk of catalog text into a high-level category using\n","    simple keyword-based rules.\n","    \"\"\"\n","    t = text.lower()\n","\n","    # Admissions\n","    if \"undergraduate admissions\" in t or \"admission requirements\" in t or \"apply for admission\" in t:\n","        return \"admissions_general\"\n","    if \"admitted to the accountancy program\" in t or \"admission to the accountancy major\" in t:\n","        return \"admissions_program_specific\"\n","\n","    # ESL / language-related content\n","    if \"english proficiency\" in t or \"english as a second language\" in t or \"esl program\" in t:\n","        return \"esl_language\"\n","\n","    # Academic calendar / dates\n","    if \"academic calendar\" in t or \"first day of the term\" in t or \"final exam period\" in t:\n","        return \"academic_calendar\"\n","\n","    # Financial / fees / scholarships\n","    if (\n","        \"tuition\" in t\n","        or \"processing fee\" in t\n","        or \"assessment fee\" in t\n","        or \"financial aid\" in t\n","        or \"scholarship\" in t\n","    ):\n","        return \"financial_fees\"\n","\n","    # Conduct and policy\n","    if \"code of conduct\" in t or \"sexual harassment\" in t or \"non-discrimination policy\" in t:\n","        return \"conduct_policy\"\n","    if \"grievance\" in t and \"formal complaint\" in t:\n","        return \"grievance_policy\"\n","    if \"satisfactory academic progress\" in t or \"academic probation\" in t or \"dismissal\" in t:\n","        return \"sap_probation_policy\"\n","\n","    # Registration / enrollment timelines\n","    if (\n","        \"course registration opens\" in t\n","        or \"late course registration\" in t\n","        or \"last day - course drop\" in t\n","    ):\n","        return \"registration_calendar\"\n","    if \"course registration\" in t and \"portal\" in t:\n","        return \"registration_procedure\"\n","\n","    # Graduation requirements\n","    if (\n","        \"total units required for the\" in t\n","        or \"total units required for the b.s.\" in t\n","        or \"total units required for the degree\" in t\n","    ):\n","        return \"graduation_requirements\"\n","    if \"must obtain a grade of\" in t and \"order to graduate\" in t:\n","        return \"graduation_academic_rules\"\n","\n","    # Course descriptions and curriculum\n","    if (\n","        \"course description\" in t\n","        or \"prerequisite:\" in t\n","        or \"this course aims to\" in t\n","        or \"this course examines\" in t\n","    ):\n","        return \"course_description\"\n","    if \"program learning outcomes\" in t or \"students receiving a bachelor of science in\" in t:\n","        return \"program_learning_outcomes\"\n","    if \"overview\" in t and (\"program\" in t or \"major\" in t):\n","        return \"program_overview\"\n","    if (\n","        \"upper division business core\" in t\n","        or \"general education units\" in t\n","        or \"requirements business majors\" in t\n","    ):\n","        return \"curriculum_structure\"\n","\n","    # Fallback category\n","    return \"general_academic\"\n","\n","\n","def infer_academic_metadata(section_name: str, first_chunk_text: str) -> Dict[str, str]:\n","    \"\"\"Infer program, college, degree, and level from a section name and\n","    the first chunk of text from that section.\n","\n","    This uses heuristics based on:\n","    - File names (e.g., accounting.xhtml → \"Accounting\").\n","    - Key phrases in the text (e.g., \"Bachelor of Science\", \"Master of Science\").\n","\n","    Parameters\n","    ----------\n","    section_name : str\n","        Filename or logical section identifier.\n","    first_chunk_text : str\n","        First chunk of text from the section, used for context.\n","\n","    Returns\n","    -------\n","    Dict[str, str]\n","        Dictionary with keys: 'program', 'college', 'degree', 'level'\n","        Values may be None if not inferable.\n","    \"\"\"\n","    metadata: Dict[str, str] = {\n","        \"program\": None,\n","        \"college\": None,\n","        \"degree\": None,\n","        \"level\": None,\n","    }\n","\n","    base = os.path.basename(section_name).lower()\n","\n","    # Infer program from filename (EPUB sections like accounting.xhtml, biology.xhtml, etc.)\n","    if base.endswith((\".xhtml\", \".html\", \".htm\")):\n","        base_no_ext = re.sub(r\"\\.x?html?$\", \"\", base, flags=re.I)\n","        if base_no_ext not in (\"index\", \"toc\", \"frontmatter\"):\n","            program_name = re.sub(r\"[_\\-]+\", \" \", base_no_ext).strip()\n","            if program_name:\n","                metadata[\"program\"] = program_name.title()\n","\n","    text_lower = (first_chunk_text or \"\").lower()\n","\n","    # Degree and level detection\n","    if \"bachelor of science\" in text_lower or \"b.s.\" in text_lower:\n","        metadata[\"degree\"] = \"B.S.\"\n","        metadata[\"level\"] = \"undergraduate\"\n","    elif \"bachelor of arts\" in text_lower or \"b.a.\" in text_lower:\n","        metadata[\"degree\"] = \"B.A.\"\n","        metadata[\"level\"] = \"undergraduate\"\n","    elif \"master of science\" in text_lower or \"m.s.\" in text_lower:\n","        metadata[\"degree\"] = \"M.S.\"\n","        metadata[\"level\"] = \"graduate\"\n","    elif \"master of professional accountancy\" in text_lower or \"mpacc\" in text_lower:\n","        metadata[\"degree\"] = \"M.P.Acc.\"\n","        metadata[\"level\"] = \"graduate\"\n","\n","    # Example of college detection (CSUN Nazarian College)\n","    if \"david nazarian college of business and economics\" in text_lower:\n","        metadata[\"college\"] = \"David Nazarian College of Business and Economics\"\n","\n","    return metadata\n","\n","\n","print(\"Classification and metadata inference helpers defined.\")"]},{"cell_type":"code","execution_count":9,"id":"c3b23a06","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3b23a06","executionInfo":{"status":"ok","timestamp":1764340300442,"user_tz":-120,"elapsed":11,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"15f15343-4dde-4998-a712-a926c1b3cafc"},"outputs":[{"output_type":"stream","name":"stdout","text":["CSUN EPUB processing function defined.\n"]}],"source":["\"\"\"\n","Step 4: Process CSUN EPUB catalog\n","\n","This function:\n","- Opens the CSUN catalog EPUB.\n","- Extracts and cleans HTML files.\n","- Chunks text by paragraphs.\n","- Infers academic metadata.\n","- Classifies each chunk.\n","- Deduplicates content across the global dataset.\n","\"\"\"\n","\n","def extract_csun_catalog_chunks(\n","    epub_path: str,\n","    seen_normalized_text: Set[str],\n","    next_record_id: int\n",") -> Tuple[List[Dict], int]:\n","    \"\"\"Extract cleaned, chunked, and annotated records from the CSUN EPUB catalog.\n","\n","    Parameters\n","    ----------\n","    epub_path : str\n","        Path to the CSUN EPUB file.\n","    seen_normalized_text : Set[str]\n","        Set of normalized text strings used to deduplicate chunks globally.\n","    next_record_id : int\n","        Starting ID value for generated records.\n","\n","    Returns\n","    -------\n","    Tuple[List[Dict], int]\n","        - List of record dictionaries for this catalog.\n","        - The next available record ID after processing.\n","    \"\"\"\n","    records: List[Dict] = []\n","\n","    if not os.path.exists(epub_path):\n","        print(f\"[WARN] CSUN EPUB not found at: {epub_path}\")\n","        return records, next_record_id\n","\n","    with ZipFile(epub_path, \"r\") as zf:\n","        html_files = [\n","            name for name in zf.namelist()\n","            if name.lower().endswith((\".xhtml\", \".html\", \".htm\"))\n","        ]\n","\n","        for section_name in sorted(html_files):\n","            try:\n","                raw_html = zf.read(section_name).decode(\"utf-8\", errors=\"ignore\")\n","            except Exception as exc:\n","                print(f\"[WARN] Failed to read {section_name}: {exc}\")\n","                continue\n","\n","            cleaned_text = clean_html_content(raw_html)\n","\n","            # Skip very small or navigation-like fragments\n","            if len(cleaned_text) < 300:\n","                continue\n","\n","            chunks = chunk_text_by_paragraph(cleaned_text, max_length=1400)\n","            if not chunks:\n","                continue\n","\n","            # Infer program metadata from the first chunk in this section\n","            section_metadata = infer_academic_metadata(section_name, chunks[0])\n","\n","            for chunk_index, chunk_text in enumerate(chunks):\n","                normalized = re.sub(r\"\\s+\", \" \", chunk_text.lower()).strip()\n","\n","                # Skip tiny or noisy chunks\n","                if len(normalized) < 100:\n","                    continue\n","\n","                # Deduplicate across entire dataset\n","                if normalized in seen_normalized_text:\n","                    continue\n","\n","                seen_normalized_text.add(normalized)\n","\n","                record = {\n","                    \"id\": next_record_id,\n","                    \"source_file\": \"csun_2025_2026_catalog\",\n","                    \"university\": \"California State University, Northridge\",\n","                    \"catalog_label\": \"2025-2026 University Catalog\",\n","                    \"section\": section_name,\n","                    \"section_chunk_index\": chunk_index,\n","                    \"category\": classify_chunk_category(chunk_text),\n","                    \"program\": section_metadata.get(\"program\"),\n","                    \"college\": section_metadata.get(\"college\"),\n","                    \"degree\": section_metadata.get(\"degree\"),\n","                    \"level\": section_metadata.get(\"level\"),\n","                    \"text\": chunk_text,\n","                }\n","\n","                records.append(record)\n","                next_record_id += 1\n","\n","    print(f\"Extracted {len(records)} chunks from CSUN catalog.\")\n","    return records, next_record_id\n","\n","\n","print(\"CSUN EPUB processing function defined.\")"]},{"cell_type":"code","execution_count":10,"id":"057654c4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"057654c4","executionInfo":{"status":"ok","timestamp":1764340304774,"user_tz":-120,"elapsed":26,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"7da6fade-ed59-44ab-9507-942a2e1a85cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["UoPeople PDF processing function defined.\n"]}],"source":["\"\"\"\n","Step 5: Process University of the People PDF catalog\n","\n","This function:\n","- Reads each page of the UoPeople catalog updates PDF.\n","- Normalizes text and preserves paragraph structure.\n","- Chunks text by paragraphs.\n","- Infers metadata where possible.\n","- Classifies each chunk.\n","- Deduplicates content across the global dataset.\n","\"\"\"\n","\n","def extract_uopeople_catalog_chunks(\n","    pdf_path: str,\n","    seen_normalized_text: Set[str],\n","    next_record_id: int\n",") -> Tuple[List[Dict], int]:\n","    \"\"\"Extract cleaned, chunked, and annotated records from the UoPeople PDF catalog.\n","\n","    Parameters\n","    ----------\n","    pdf_path : str\n","        Path to the UoPeople PDF file.\n","    seen_normalized_text : Set[str]\n","        Set of normalized text strings used to deduplicate chunks globally.\n","    next_record_id : int\n","        Starting ID value for generated records.\n","\n","    Returns\n","    -------\n","    Tuple[List[Dict], int]\n","        - List of record dictionaries for this catalog.\n","        - The next available record ID after processing.\n","    \"\"\"\n","    records: List[Dict] = []\n","\n","    if not os.path.exists(pdf_path):\n","        print(f\"[WARN] UoPeople PDF not found at: {pdf_path}\")\n","        return records, next_record_id\n","\n","    reader = PdfReader(pdf_path)\n","\n","    for page_index, page in enumerate(reader.pages):\n","        try:\n","            page_text = page.extract_text() or \"\"\n","        except Exception as exc:\n","            print(f\"[WARN] Failed to extract text from page {page_index + 1}: {exc}\")\n","            continue\n","\n","        # Normalize whitespace and newlines\n","        page_text = page_text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n","        page_text = re.sub(r\"[ \\t]+\", \" \", page_text)\n","        page_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", page_text)\n","\n","        if len(page_text) < 300:\n","            # Skip pages with very little content\n","            continue\n","\n","        chunks = chunk_text_by_paragraph(page_text, max_length=1400)\n","        if not chunks:\n","            continue\n","\n","        section_name = f\"page_{page_index + 1}\"\n","        section_metadata = infer_academic_metadata(section_name, chunks[0])\n","\n","        for chunk_index, chunk_text in enumerate(chunks):\n","            normalized = re.sub(r\"\\s+\", \" \", chunk_text.lower()).strip()\n","\n","            if len(normalized) < 100:\n","                continue\n","\n","            if normalized in seen_normalized_text:\n","                continue\n","\n","            seen_normalized_text.add(normalized)\n","\n","            record = {\n","                \"id\": next_record_id,\n","                \"source_file\": \"uopeople_ug_catalog_updates_2024_2025\",\n","                \"university\": \"University of the People\",\n","                \"catalog_label\": \"2025-26 Undergraduate Catalog (Updates)\",\n","                \"section\": section_name,\n","                \"section_chunk_index\": chunk_index,\n","                \"category\": classify_chunk_category(chunk_text),\n","                \"program\": section_metadata.get(\"program\"),\n","                \"college\": section_metadata.get(\"college\"),\n","                \"degree\": section_metadata.get(\"degree\"),\n","                \"level\": section_metadata.get(\"level\"),\n","                \"text\": chunk_text,\n","            }\n","\n","            records.append(record)\n","            next_record_id += 1\n","\n","    print(f\"Extracted {len(records)} chunks from UoPeople catalog.\")\n","    return records, next_record_id\n","\n","\n","print(\"UoPeople PDF processing function defined.\")"]},{"cell_type":"code","execution_count":11,"id":"5973c04f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5973c04f","executionInfo":{"status":"ok","timestamp":1764340318446,"user_tz":-120,"elapsed":10226,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"cf7eb863-96ed-4638-bdf0-e1ff19d8b238"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted 4597 chunks from CSUN catalog.\n","Extracted 454 chunks from UoPeople catalog.\n","Total combined chunks: 5051\n","Dataset written to: /content/drive/MyDrive/DAB_RAG_ZakyProject/data/academic_advisor_rag_dataset.json\n"]}],"source":["\"\"\"\n","Step 6: Build the full academic advisor RAG dataset\n","\n","This function:\n","- Initializes a global deduplication set.\n","- Runs the CSUN EPUB and UoPeople PDF extractors.\n","- Combines all records into a single list.\n","- Saves the result as a JSON file.\n","\n","We refer to this as the *dataset build pipeline*.\n","\"\"\"\n","\n","def run_dataset_build_pipeline() -> List[Dict]:\n","    \"\"\"Run the dataset build pipeline for the academic advisor RAG dataset.\n","\n","    Returns\n","    -------\n","    List[Dict]\n","        List of all records that were generated and saved to JSON.\n","    \"\"\"\n","    all_records: List[Dict] = []\n","    seen_normalized_text: Set[str] = set()\n","    next_record_id: int = 1\n","\n","    # Process CSUN catalog (EPUB)\n","    csun_records, next_record_id = extract_csun_catalog_chunks(\n","        epub_path=CSUN_EPUB_PATH,\n","        seen_normalized_text=seen_normalized_text,\n","        next_record_id=next_record_id,\n","    )\n","    all_records.extend(csun_records)\n","\n","    # Process UoPeople catalog (PDF)\n","    uopeople_records, next_record_id = extract_uopeople_catalog_chunks(\n","        pdf_path=UOPEOPLE_PDF_PATH,\n","        seen_normalized_text=seen_normalized_text,\n","        next_record_id=next_record_id,\n","    )\n","    all_records.extend(uopeople_records)\n","\n","    print(f\"Total combined chunks: {len(all_records)}\")\n","\n","    # Save to JSON file\n","    with open(OUTPUT_JSON_PATH, \"w\", encoding=\"utf-8\") as output_file:\n","        json.dump(all_records, output_file, ensure_ascii=False, indent=2)\n","\n","    print(f\"Dataset written to: {OUTPUT_JSON_PATH}\")\n","    return all_records\n","\n","\n","# Run the pipeline\n","academic_advisor_records = run_dataset_build_pipeline()"]},{"cell_type":"code","execution_count":12,"id":"bb15a57a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bb15a57a","executionInfo":{"status":"ok","timestamp":1764340337357,"user_tz":-120,"elapsed":24,"user":{"displayName":"Dana Ismail","userId":"06029342386178835602"}},"outputId":"f2868419-9b55-44d4-9c1f-3dec07029825"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of records: 5051\n","--------------------------------------------------------------------------------\n","ID:          1\n","University:  California State University, Northridge\n","Source file: csun_2025_2026_catalog\n","Section:     OEBPS/accounting.xhtml\n","Chunk idx:   0\n","Category:    general_academic\n","Program:     Accounting\n","Degree:      B.S.\n","Level:       undergraduate\n","Text preview:\n","Accounting\n","Accounting\n","David Nazarian College of Business and Economics\n","Department of Accounting\n","Chair: Rishma Vedd\n","Bookstein Hall (BB) 3123\n","(818) 677-2461\n","Master of Professional Accountancy\n","Director: Rafael Efrat\n","Bookstein Hall (BB) 3123\n","(818) 677-2461\n","Master of Science in Taxation\n","Bookstein Chair in Taxation: Rafael Efrat\n","Bookstein Hall (BB) 3123\n","(818) 677-5488\n","EY Center for Careers in Accounting ...\n","--------------------------------------------------------------------------------\n","ID:          2\n","University:  California State University, Northridge\n","Source file: csun_2025_2026_catalog\n","Section:     OEBPS/accounting.xhtml\n","Chunk idx:   1\n","Category:    general_academic\n","Program:     Accounting\n","Degree:      B.S.\n","Level:       undergraduate\n","Text preview:\n","The Bachelor of Science in Accountancy (BSA) degree prepares students with the competencies, skills and knowledge necessary in the accountancy profession. Students complete a rigorous program in accounting that develops their technical proficiency; ethical leadership; professional responsibilities; communication; and critical-thinking, interpersonal and technological skills.\n","The Master of Professi ...\n","--------------------------------------------------------------------------------\n","ID:          3\n","University:  California State University, Northridge\n","Source file: csun_2025_2026_catalog\n","Section:     OEBPS/accounting.xhtml\n","Chunk idx:   2\n","Category:    general_academic\n","Program:     Accounting\n","Degree:      B.S.\n","Level:       undergraduate\n","Text preview:\n","Academic advisement helps students meet their academic goals and graduate in a timely manner. The Nazarian College Student Services Center/EOP Satellite provides academic advisement for Nazarian College majors during their time at CSUN. Furthermore, Nazarian College Student Services Center/EOP Satellite provides specialized support and retention services for Nazarian College students admitted to t ...\n","--------------------------------------------------------------------------------\n","ID:          4\n","University:  California State University, Northridge\n","Source file: csun_2025_2026_catalog\n","Section:     OEBPS/accounting.xhtml\n","Chunk idx:   3\n","Category:    general_academic\n","Program:     Accounting\n","Degree:      B.S.\n","Level:       undergraduate\n","Text preview:\n","The EY Center for Careers in Accounting at California State University, Northridge, provides specialized career and job search services to CSUN students and alumni. As a bridge from college life to the world of work, it is our mission to support the exploration of career and academic options, and the development of job search skills, and to facilitate connections between employers and students tha ...\n","--------------------------------------------------------------------------------\n","ID:          5\n","University:  California State University, Northridge\n","Source file: csun_2025_2026_catalog\n","Section:     OEBPS/accounting.xhtml\n","Chunk idx:   4\n","Category:    general_academic\n","Program:     Accounting\n","Degree:      B.S.\n","Level:       undergraduate\n","Text preview:\n","The MPAcc program helps graduates meet California’s 150-hour requirement for CPA licensure. In addition, the program prepares graduates to pursue a variety of accounting career options, including public accounting, private industry, government and nonprofit.\n","Master of Science in Taxation (MST)\n","The field of taxation offers stimulating and challenging work that is constantly evolving. Career opportu ...\n"]}],"source":["\"\"\"\n","Step 7: Inspect a few sample records\n","\n","This is helpful in the project report to demonstrate\n","what the final RAG-ready entries look like.\n","\"\"\"\n","\n","print(f\"Number of records: {len(academic_advisor_records)}\")\n","\n","# Show a few sample records\n","for record in academic_advisor_records[:5]:\n","    print(\"-\" * 80)\n","    print(f\"ID:          {record['id']}\")\n","    print(f\"University:  {record['university']}\")\n","    print(f\"Source file: {record['source_file']}\")\n","    print(f\"Section:     {record['section']}\")\n","    print(f\"Chunk idx:   {record['section_chunk_index']}\")\n","    print(f\"Category:    {record['category']}\")\n","    print(f\"Program:     {record['program']}\")\n","    print(f\"Degree:      {record['degree']}\")\n","    print(f\"Level:       {record['level']}\")\n","    print(\"Text preview:\")\n","    print(record[\"text\"][:400], \"...\")"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}